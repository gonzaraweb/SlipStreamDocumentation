Performance Example using Apache
================================

Goal
====

The goal of this tutorial is to demonstrate how SlipStream™ can be used
to automate performance testing, reusing existing deployments. A single
parameter is required to instruct SlipStream™ to instantiate several
instances of a single image, without needing any duplication of metadata
in SlipStream™. We will use this feature to define a performance test,
where several test suites will be launched together to create a higher
load on the Apache server we already created in the *Simple
Client/Server* tutorial. With a slight modification to the test suite,
such that instead of downloading a document once, we will loop over a
few times such that we can study the behaviour of Apache (or any server)
under load.

If you have not performed the *Simple Client/Server* tutorial, you can
find a solution of the tutorial in the area `Public/HelloWorld`.
However, we assume that you have acquired the knowledge presented in
that first tutorial.

Create new Project
==================

In your home project (refer to the *Simple Client/Server* tutorial),
create another project called, say, `Performance_Tutorial`.

Create a new Deployment Module
==============================

Create a new deployment module in the `Performance_Tutorial` project
called, say, `deployment`. In this deployment we need to add two nodes
corresponding to our Apache server and a test suite. To start with, we
will reuse the Simple Client/Server tutorial test suite.

In this tutorial, we introduce the concept of *multiplicity*. This means
that by setting a multiplicity value on a node, we instruct SlipStream™
to instantiate at runtime several times the same virtual machine, but
with a distinct image names. When instantiating nodes with multiplicity,
SlipStream™ creates entries in the run instance in the form
`<nodename>-<i>` where `i` is an index ranging from 1 to the value given
to the multiplicity field.

To do this follow these steps:

1.  Add a new node, by clicking on the *Add Node* button. This will open
    the chooser window. In the chooser, navigate and select your apache
    image. You will only be able to select a module of type Image. Now
    name this node `apache`.

2.  Do the same for the test suite as we have done for the Simple
    Client/Server tutorial. Name it `testsuite`.

3.  On the `testsuite` node, set the *Multiplicity* field to `3`. This
    means that have defined a testsuite node that will represent 3
    distinct testsuite image instances. At runtime, the three testsuite
    will be called respectively: `testsuite-1`, `testsuite-2` and
    `testsuite-3`.

4.  Here as well, we need to resolve the testsuite's input parameter
    requirement. Set the *Linked to* field of the `webserver.hostname`
    parameter to `apache:hostname` (where `apache` corresponds to the
    name of the node you have given in the first step). This means that
    when the `apache:hostname` parameter will be set as part of the
    apache node execution sequence, the `webserver.hostname` parameter
    of the testsuite nodes will also be set, linking them together.

5.  Save the deployment.

We are now ready to submit our new deployment test.

Execute Distributed Test
========================

To launch the distributed test, simply click on the "Run" button of the
deployment you have created above.

The execution instance created for each submission allows you to track
the progress of the distributed test. When the test is completed, you
can access the reports generated by the different nodes, by clicking on
the "Results" link.

In the report, you will now see an entry for each test suite, containing
the specific report of the test suite instance.

While this is interesting, we can do better. Next, we will modify the
test suite to increase the load.

Increasing the Load on the Server
=================================

Instead of simply reusing the test suite from the simple client/server
tutorial, we could upgrade the test suite, in which we could for example
loop a few times over getting the data, and record the access time for
each retrieval. We could also perform this data retrieval from several
threads, to make sure we saturate the network, and this by increasing
the threads over time. By resubmitting this deployment and varying the
multiplicity number, we should see how the number of clients and
requests affect the web server's response time. Finally, we could also
increase the size of the retrieved document, to increase again the load
of the server and the network. We leave this exercise to the user and
are looking forward to hearing your solutions.
